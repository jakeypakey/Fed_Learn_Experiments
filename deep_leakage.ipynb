{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models,datasets,transforms\n",
    "from leakageFuncs import Network, trainAndReleaseGrads\n",
    "batchSize=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainL = datasets.MNIST(\"./data\",train=True,download=True,transform=transforms.Compose([transforms.ToTensor(),\n",
    "       transforms.Normalize((0.13707,),(.3081,))]))\n",
    "trainData = enumerate(DataLoader(trainL,batch_size=batchSize,shuffle=True))\n",
    "\n",
    "testL = datasets.MNIST(\"./data\",train=False,download=True,transform=transforms.Compose([transforms.ToTensor(),\n",
    "       transforms.Normalize((0.13707,),(.3081,))]))\n",
    "testData = enumerate(DataLoader(testL,batch_size=batchSize,shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): Sigmoid()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Sigmoid()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=57600, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(),lr=1e-3)\n",
    "crit = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: 0, loss: 2.3317248821258545\n",
      "Example: 1000, loss: 0.8306520581245422\n",
      "Example: 2000, loss: 3.3506569862365723\n",
      "Example: 3000, loss: 0.4169065058231354\n",
      "Example: 4000, loss: 1.7832446098327637\n",
      "Example: 5000, loss: 0.756360650062561\n"
     ]
    }
   ],
   "source": [
    "model, grad = trainAndReleaseGrads(model,trainData,5000,nn.CrossEntropyLoss(),torch.optim.SGD(model.parameters(),lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.randn(trainL.data[0].shape)\n",
    "y = torch.randn(10)\n",
    "toImage = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=140x140 at 0x7FDFAFE14A00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#our image to start\n",
    "im = toImage(x)\n",
    "display(im.resize((5 * 28, 5 * 28), Image.NEAREST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
